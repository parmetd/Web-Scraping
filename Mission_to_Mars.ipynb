{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import time\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Driver\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    "### 1.1 - NASA Mars News\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest) and collect the latest News Title and Paragraph Text. \n",
    "\n",
    "### 1.2 - Mars Space Images\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "* Make sure to find the image url to the full size .jpg image.\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "### 1.3 - Mars Weather\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called mars_weather.\n",
    "\n",
    "### 1.4 - Mars Facts\n",
    "* Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "* Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "### 1.5 - Mars Hemispheres\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "* click into each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping URL\n",
    "Mars_News_URL = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the latest news information include: news date, news title and news article. \n",
    "\n",
    "def get_mars_news(URL):\n",
    "    try:\n",
    "        \n",
    "        browser.visit(URL)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "\n",
    "        # Find the latest news content\n",
    "        news_list = soup.body.find('ul',class_='item_list')\n",
    "        latest_news = news_list.find('li',class_='slide')\n",
    "        latest_news_content = latest_news.find('div',class_='list_text')\n",
    "\n",
    "        # Find latest news Date, Title and Paragraph\n",
    "        latest_news_date = latest_news_content.find('div',class_='list_date').text\n",
    "        latest_news_title = latest_news_content.find('div',class_='content_title').text\n",
    "        latest_news_article = latest_news_content.find('div',class_='article_teaser_body').text\n",
    "        \n",
    "        return {\"news_date\":latest_news_date,\"news_title\":latest_news_title,\"news_article\":latest_news_article}\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Web Scraping Fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_date': 'February 13, 2019', 'news_title': \"Six Things to Know About NASA's Opportunity Rover\", 'news_article': \"Opportunity's mission is complete. Here are highlights from its time on Mars.\"}\n"
     ]
    }
   ],
   "source": [
    "print(get_mars_news(Mars_News_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping URL\n",
    "Mars_Image_URL = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the image URL from JPL page. \n",
    "def get_mars_image(URL):\n",
    "    \n",
    "    # Press the full image button\n",
    "    browser.visit(URL)\n",
    "    button = browser.find_by_id(\"full_image\")\n",
    "    button.click()\n",
    "    time.sleep(1) \n",
    "\n",
    "    html_string = browser.html\n",
    "\n",
    "    # Web scraping find the first image\n",
    "    soup = bs(html_string, 'lxml')\n",
    "\n",
    "    fancy_box = soup.find('div',id='fancybox-thumbs')\n",
    "    image_object_list = fancy_box.find_all('a',class_='ready')\n",
    "    \n",
    "    image_select = 0\n",
    "    count = 0\n",
    "    \n",
    "    for image_object in image_object_list: \n",
    "        \n",
    "        try: \n",
    "        \n",
    "            select_image_url = \"https://www.jpl.nasa.gov\" + image_object.img['src']          \n",
    "            image_select = 1  \n",
    "            return select_image_url\n",
    "        \n",
    "        except:   \n",
    "            \n",
    "            count = count + 1\n",
    "            print(f\"Try the {count}-th time, fail\")\n",
    "        \n",
    "        if image_select == 1:     \n",
    "            break       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA20063_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "print(get_mars_image(Mars_Image_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping URL\n",
    "Mars_Weather_URL = \"https://twitter.com/marswxreport?lang=en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the Mars weather information. \n",
    "def get_mars_weather(URL):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        browser.visit(URL)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "        \n",
    "        weather_container_list = soup.find_all('li',class_='js-stream-item')\n",
    "        \n",
    "        for weather_container in weather_container_list: \n",
    "            \n",
    "            weather_publisher_name = weather_container.find('strong',class_='fullname').text.strip()\n",
    "            \n",
    "            if weather_publisher_name == \"Mars Weather\":\n",
    "        \n",
    "                mars_weather = weather_container.find('div',class_='js-tweet-text-container').text.strip()\n",
    "            \n",
    "                break\n",
    "        \n",
    "        return mars_weather.split('pic')[0]\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Web Scraping Fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2319 (2019-02-13), high -17C/1F, low -72C/-97F, pressure at 8.12 hPa, daylight 06:46-18:52\n"
     ]
    }
   ],
   "source": [
    "print(get_mars_weather(Mars_Weather_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping URL\n",
    "Mars_Facts_URL = \"https://space-facts.com/mars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the Mars Facts information. \n",
    "def get_mars_facts(URL): \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        browser.visit(URL)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "\n",
    "        mars_fact = {}\n",
    "        table = soup.find('table',id='tablepress-mars')\n",
    "        \n",
    "        for table_row in table.find_all('tr'):\n",
    "            \n",
    "            table_row_value = table_row.find_all('td')\n",
    "            \n",
    "            key = table_row_value[0].text.strip().replace(':','')\n",
    "            value = table_row_value[1].text.strip()\n",
    "            \n",
    "            mars_fact = {**mars_fact,**{key:value}}\n",
    "            \n",
    "        return mars_fact\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        print(\"Web Scraping Fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Equatorial Diameter': '6,792 km', 'Polar Diameter': '6,752 km', 'Mass': '6.42 x 10^23 kg (10.7% Earth)', 'Moons': '2 (Phobos & Deimos)', 'Orbit Distance': '227,943,824 km (1.52 AU)', 'Orbit Period': '687 days (1.9 years)', 'Surface Temperature': '-153 to 20 Â°C', 'First Record': '2nd millennium BC', 'Recorded By': 'Egyptian astronomers'}\n"
     ]
    }
   ],
   "source": [
    "print(get_mars_facts(Mars_Facts_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 - Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping URL\n",
    "Mars_Hemispheres_URL = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape the images for each of Mar's hemispheres.\n",
    "def get_mars_hemispheres(URL):\n",
    "    \n",
    "    mars_hemispheres = []\n",
    "    \n",
    "    try:\n",
    "        browser.visit(URL)     \n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "        \n",
    "        image_group = soup.find('div',class_='collapsible results')\n",
    "        \n",
    "        image_object_list = image_group.find_all('div',class_='item')\n",
    "        \n",
    "        for image_object in image_object_list:\n",
    "            \n",
    "            image_title = image_object.find('h3').text.strip()\n",
    "            \n",
    "            # Extract full image\n",
    "            full_image_url = 'https://astrogeology.usgs.gov'+ image_object.find('a')['href'] \n",
    "            browser.visit(full_image_url)\n",
    "\n",
    "            full_image_html_string = browser.html\n",
    "            full_image_soup = bs(full_image_html_string, 'lxml')\n",
    "            \n",
    "            image_url='https://astrogeology.usgs.gov' + str(full_image_soup.find('img','wide-image')['src'])\n",
    "            \n",
    "            mars_hemispheres.append({\"image_title\": image_title, \"image_url\": image_url})\n",
    "            \n",
    "            browser.back()\n",
    "            \n",
    "        return mars_hemispheres   \n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Web Scraping Fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_title': 'Cerberus Hemisphere Enhanced', 'image_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'}, {'image_title': 'Schiaparelli Hemisphere Enhanced', 'image_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'}, {'image_title': 'Syrtis Major Hemisphere Enhanced', 'image_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'}, {'image_title': 'Valles Marineris Hemisphere Enhanced', 'image_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "print(get_mars_hemispheres(Mars_Hemispheres_URL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
